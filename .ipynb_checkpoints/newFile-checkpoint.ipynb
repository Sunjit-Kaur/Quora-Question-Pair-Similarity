{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e478536-bd4d-4184-b0d1-34e54fbb078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "def normalizedata(X_train):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    return X_train[:,~np.any(np.isnan(X_train), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fd9bd8-5c4c-40a4-a489-e83cc9729c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "def normalizedata(X_train):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    return X_train[:,~np.any(np.isnan(X_train), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277ec7b8-493a-41a3-8e47-ccfb9f2f52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allinput():\n",
    "  inpf=[]\n",
    "  fname='02_new_ranksums_wiki100.csv'\n",
    "  data=np.genfromtxt(fname,delimiter=',')\n",
    "  inpf.append(normalizedata(data[:,0:74]))\n",
    "  inpf.append(normalizedata(data[:,74:-1]))\n",
    "  lab=np.array(data[:,-1])\n",
    "  inpf.append(lab)\n",
    "  return inpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62fbdf1-3316-4ff5-8760-9b5cfbf8e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inval=[]\n",
    "a=[0,1]\n",
    "inval.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d97d8c-5783-4d0e-879f-379b696360e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "XGB = XGBClassifier(random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e1e3e8-c6d9-4385-b352-9b587bdc766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(trdata):\n",
    "  model=[]\n",
    "  model.append(MultinomialNB())\n",
    "  model.append(BernoulliNB())\n",
    "  model.append(GaussianNB())\n",
    "  model.append(DecisionTreeClassifier())\n",
    "  model.append(LogisticRegression())\n",
    "  model.append(KNeighborsClassifier())\n",
    "  model.append(svm.SVC(kernel=\"linear\",probability=True))\n",
    "  model.append(svm.SVC(kernel=\"poly\",probability=True))\n",
    "  model.append(svm.SVC(kernel=\"rbf\",probability=True))\n",
    "  model.append(BaggingClassifier(MultinomialNB(),max_samples=0.5, max_features=0.5))\n",
    "  model.append(BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5, max_features=0.5))\n",
    "  model.append(BaggingClassifier(LogisticRegression(),max_samples=0.5, max_features=0.5))\n",
    "  model.append(BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5))\n",
    "  model.append(RandomForestClassifier(n_estimators=10))\n",
    "  model.append(ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0))\n",
    "  model.append(AdaBoostClassifier(n_estimators=10))\n",
    "  model.append(GradientBoostingClassifier(n_estimators=10, learning_rate=1.0,max_depth=1, random_state=0))\n",
    "  model.append(XGBClassifier())\n",
    "  model.append(LGBMClassifier(metric='auc',verbose=-1))\n",
    "  model.append(MLPClassifier(solver='lbfgs', hidden_layer_sizes=(trdata.shape[1], 2), random_state=1,max_iter=1500))\n",
    "  model.append(MLPClassifier(solver='sgd', hidden_layer_sizes=(trdata.shape[1], 2), random_state=1,max_iter=1500))\n",
    "  model.append(MLPClassifier(solver='adam', hidden_layer_sizes=(trdata.shape[1], 2), random_state=1,max_iter=1500))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6824af32-8233-410d-97fd-71eda2c0a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "def modelst2(m,X,a):\n",
    "  clf_1 = m[0]\n",
    "  clf_1_transformer = FunctionTransformer(lambda X: X[:,:a])\n",
    "  tclf_1 = Pipeline([('transformer_1', clf_1_transformer), ('clf_1', clf_1)])\n",
    "  clf_2 = m[1]\n",
    "  clf_2_transformer = FunctionTransformer(lambda X: X[:,a:])\n",
    "  tclf_2 = Pipeline([('transformer_2', clf_2_transformer), ('clf_2', clf_2)])\n",
    "  sclf = StackingClassifier([('tclf_1', tclf_1), ('tclf_2', tclf_2)],final_estimator=XGB,cv=3)\n",
    "  return sclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75abe37d-8743-4658-bf77-dd1c3b8c1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "def modelst2(m,X,a):\n",
    "  clf_1 = m[0]\n",
    "  clf_1_transformer = FunctionTransformer(lambda X: X[:,:a])\n",
    "  tclf_1 = Pipeline([('transformer_1', clf_1_transformer), ('clf_1', clf_1)])\n",
    "  clf_2 = m[1]\n",
    "  clf_2_transformer = FunctionTransformer(lambda X: X[:,a:])\n",
    "  tclf_2 = Pipeline([('transformer_2', clf_2_transformer), ('clf_2', clf_2)])\n",
    "  sclf = StackingClassifier([('tclf_1', tclf_1), ('tclf_2', tclf_2)],final_estimator=XGB,cv=3)\n",
    "  return sclf\n",
    "\n",
    "def modelst3(m,X,a,b):\n",
    "  clf_1 = m[0]\n",
    "  clf_1_transformer = FunctionTransformer(lambda X: X[:,:a])\n",
    "  tclf_1 = Pipeline([('transformer_1', clf_1_transformer), ('clf_1', clf_1)])\n",
    "  clf_2 = m[1]\n",
    "  clf_2_transformer = FunctionTransformer(lambda X: X[:,a:b])\n",
    "  tclf_2 = Pipeline([('transformer_2', clf_2_transformer), ('clf_2', clf_2)])\n",
    "  clf_3 = m[2]\n",
    "  clf_3_transformer = FunctionTransformer(lambda X: X[:,b:])\n",
    "  tclf_3 = Pipeline([('transformer_2', clf_3_transformer), ('clf_3', clf_3)])\n",
    "  sclf = StackingClassifier([('tclf_1', tclf_1), ('tclf_2', tclf_2), ('tclf_3', tclf_3)],final_estimator=XGB,cv=3)\n",
    "  return sclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a744db4-f0b2-43f2-841e-01d911895230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model2(x,a):\n",
    "  model1=final_model(x[:,:a])\n",
    "  model2=final_model(x[:,a:])\n",
    "  model3=final_model(x[:,0:2])\n",
    "  model=[]\n",
    "  for i in range(0,22):\n",
    "    m=[]\n",
    "    m.append(model1[i])\n",
    "    m.append(model2[i])\n",
    "    m.append(model3[i])\n",
    "    model.append(modelst2(m,x,a))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e16c54-d85c-414f-a73d-0669c4c7a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_model(model,trdata,tract,tsdata):\n",
    "  pred=np.zeros((np.shape(tsdata)[0],22))\n",
    "  pred1=np.zeros((np.shape(tsdata)[0],22))\n",
    "  for i in range(0,22):\n",
    "    m=model[i]\n",
    "    m.fit(trdata,tract)\n",
    "    pred[:,i]=m.predict(tsdata)\n",
    "    pred1[:,i]=m.predict_proba(tsdata)[:,1]\n",
    "  return pred,pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46306564-4ed7-4252-b3a6-4a061e6af37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "kf = KFold(3)\n",
    "def final_tr_model(data,bugs,cs,a,b):\n",
    "  predv=np.zeros((np.shape(data)[0],23))\n",
    "  predv1=np.zeros((np.shape(data)[0],23))\n",
    "  model=final_model2(data,a)\n",
    "  list1 = [i for i in range(np.shape(data)[0])]\n",
    "  in1=sample(list1,np.shape(data)[0])\n",
    "  data=data[in1,:]\n",
    "  bugs=bugs[in1]\n",
    "  for train_index, test_index in kf.split(data):\n",
    "    trainX=data[train_index,:]\n",
    "    testX=data[test_index,:]\n",
    "    tract=bugs[train_index]\n",
    "    tsact=bugs[test_index]\n",
    "    pred,pred1=tr_model(model,trainX,tract,testX)\n",
    "    predv[test_index,0:22]=pred\n",
    "    predv[test_index,22]=tsact\n",
    "    predv1[test_index,0:22]=pred1\n",
    "    predv1[test_index,22]=tsact\n",
    "  return predv,predv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "748eaaf6-6bc8-4a51-a1d3-a579046f4247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "for p in range(0,1):\n",
    "  inpf=allinput()\n",
    "  nor=np.shape(inpf[0])[0]\n",
    "  predv=np.zeros((nor,23))\n",
    "  predv1=np.zeros((nor,23))\n",
    "  for i in range(0,len(inval)):\n",
    "    print(i)\n",
    "    if len(inval[i])==2:\n",
    "      x=[]\n",
    "      x.append(inpf[inval[i][0]])\n",
    "      x.append(inpf[inval[i][1]])\n",
    "      x1=np.concatenate((x[0], x[1]), axis=1)\n",
    "      predv,predv1=final_tr_model(x1,inpf[-1],1,np.shape(x[0])[1],0)\n",
    "    fname='pred'+str(p)+'_'+str(i)+'_pred.csv'\n",
    "    np.savetxt(fname,predv, delimiter=',', fmt='%f')\n",
    "    fname='pred'+str(p)+'_'+str(i)+'_predp.csv'\n",
    "    np.savetxt(fname,predv1, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41178f3-fdfa-41b1-b708-8e51e90d73da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpf=allinput()\n",
    "np.max(inpf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4244a54-3e12-4e34-b379-9a143c9c4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 0\n",
      "65.85 0.7198058975467845\n",
      "63.349999999999994 0.6828778199744817\n",
      "65.05 0.7083274759920548\n",
      "67.30000000000001 0.6756601447183593\n",
      "66.25 0.738516481216982\n",
      "69.95 0.7659288384006936\n",
      "66.85 0.7306544089951592\n",
      "65.2 0.7092015165058982\n",
      "68.60000000000001 0.7607023014790546\n",
      "65.3 0.7188669344410594\n",
      "68.10000000000001 0.7507991917405586\n",
      "67.10000000000001 0.7485510457902796\n",
      "68.0 0.7476571529136293\n",
      "66.75 0.7347171682160452\n",
      "68.85 0.7668484856939581\n",
      "67.10000000000001 0.7529180290574207\n",
      "67.95 0.7444196081250892\n",
      "68.4 0.77242109758885\n",
      "67.75 0.7532013276401764\n",
      "61.8 0.5936892021389043\n",
      "58.550000000000004 0.5283711726522435\n",
      "63.949999999999996 0.7181822961993993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,accuracy_score\n",
    "    )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,accuracy_score\n",
    "    )\n",
    "aucv=np.zeros((1,22))\n",
    "for k in range(0,1):\n",
    "  for i in range(0,1):\n",
    "    fname='pred'+str(k)+'_'+str(i)+'_pred.csv'\n",
    "    data=np.genfromtxt(fname,delimiter=',')\n",
    "    fname='pred'+str(k)+'_'+str(i)+'_predp.csv'\n",
    "    data1=np.genfromtxt(fname,delimiter=',')\n",
    "    print('---------------',i)\n",
    "    for j in range(0,22):\n",
    "      fpr, tpr, _ = roc_curve(data1[:,-1],data1[:,j])\n",
    "      aucv[i,j]=auc(fpr, tpr)\n",
    "      print(accuracy_score(data[:,j],data[:,-1])*100,auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
