{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d913573-4da9-4905-aa92-847878d3f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a3d16d-f1ad-453f-a6ad-5d41cf338aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c58574-c634-4824-8bb3-f2aa59a5c4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404351, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260db2f3-f367-4be7-8576-16a8c735b758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65359a2d-828f-438b-9041-1f3566a028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new data frame with 3000 rows from df\n",
    "new_df = df.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18110430-a824-4b37-afe4-80c99205f117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222905</th>\n",
       "      <td>222905</td>\n",
       "      <td>439350</td>\n",
       "      <td>439351</td>\n",
       "      <td>What is senior scientist salary in amsterdam?</td>\n",
       "      <td>How do I select in Ranji or under-19 from vara...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174308</th>\n",
       "      <td>174308</td>\n",
       "      <td>344378</td>\n",
       "      <td>344379</td>\n",
       "      <td>How can evaporated milk be substituted for con...</td>\n",
       "      <td>Can you substitute condensed milk for evaporat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>279667</td>\n",
       "      <td>549801</td>\n",
       "      <td>549802</td>\n",
       "      <td>What purpose does the amplitude of an electric...</td>\n",
       "      <td>Is Guys Attracts more to Sexy Shemale?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>38938</td>\n",
       "      <td>77572</td>\n",
       "      <td>77573</td>\n",
       "      <td>How much salad should you eat per meal?</td>\n",
       "      <td>Why would a tuna salad recipe say to mix until...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123887</th>\n",
       "      <td>123887</td>\n",
       "      <td>245475</td>\n",
       "      <td>245476</td>\n",
       "      <td>What are dowels in construction?</td>\n",
       "      <td>Can an entrepreneur be effective at building b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "222905  222905  439350  439351   \n",
       "174308  174308  344378  344379   \n",
       "279667  279667  549801  549802   \n",
       "38938    38938   77572   77573   \n",
       "123887  123887  245475  245476   \n",
       "\n",
       "                                                question1  \\\n",
       "222905      What is senior scientist salary in amsterdam?   \n",
       "174308  How can evaporated milk be substituted for con...   \n",
       "279667  What purpose does the amplitude of an electric...   \n",
       "38938             How much salad should you eat per meal?   \n",
       "123887                   What are dowels in construction?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "222905  How do I select in Ranji or under-19 from vara...             0  \n",
       "174308  Can you substitute condensed milk for evaporat...             0  \n",
       "279667             Is Guys Attracts more to Sexy Shemale?             0  \n",
       "38938   Why would a tuna salad recipe say to mix until...             0  \n",
       "123887  Can an entrepreneur be effective at building b...             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82823e48-6abb-4331-a1bd-3df21b0e97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eeffef0-4266-4455-867f-d1c99cf162e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "    q = str(q).lower().strip()\n",
    "\n",
    "    #Replace special characters with strings\n",
    "    q = q.replace('%',' percent ')\n",
    "    q = q.replace('@',' at ')\n",
    "    q = q.replace('$',' dollar ')\n",
    "    q = q.replace('₹',' rupee ')\n",
    "\n",
    "    #the pattern '[math]' appears very freq in whole dataset\n",
    "    q = q.replace('[math]','')\n",
    "\n",
    "    # replacing some numbers with their string equivalent\n",
    "    q = q.replace(',000,000,000 ', 'B ')\n",
    "    q = q.replace(',000,000 ', 'M ')\n",
    "    q = q.replace(',000 ', 'K ')\n",
    "    q = re.sub(r'([0-9]+)000000000', r'\\1B', q)\n",
    "    q = re.sub(r'([0-9]+)000000', r'\\1M', q)\n",
    "    q = re.sub(r'([0-9]+)000', r'\\1K', q)\n",
    "\n",
    "    # decontracting words \n",
    "    # reference : wikipedia,stack overflow\n",
    "    expand = {\n",
    "        \"ain't\": \"am not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"can't\": \"can not\",\n",
    "        \"can't've\": \"can not have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is\",\n",
    "        \"i'd\": \"i would\",\n",
    "        \"i'd've\": \"i would have\",\n",
    "        \"i'll\": \"i will\",\n",
    "        \"i'll've\": \"i will have\",\n",
    "        \"i'm\": \"i am\",\n",
    "        \"i've\": \"i have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"it'll've\": \"it will have\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\",\n",
    "        \"she'll've\": \"she will have\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so as\",\n",
    "        \"that'd\": \"that would\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"there'd\": \"there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there is\",\n",
    "        \"they'd\": \"they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they will\",\n",
    "        \"they'll've\": \"they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\",\n",
    "        \"what'll've\": \"what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who will\",\n",
    "        \"who'll've\": \"who will have\",\n",
    "        \"who's\": \"who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'll've\": \"you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'re\": \" are\",\n",
    "        \"'ll\": \" will\"\n",
    "    }\n",
    "    q_expand = []\n",
    "    for word in q.split():\n",
    "        if word in expand:\n",
    "            word = expand[word]\n",
    "        q_expand.append(word)\n",
    "    q = ' '.join(q_expand)\n",
    "\n",
    "    #Removing html tags\n",
    "    q = BeautifulSoup(q)\n",
    "    q = q.get_text()\n",
    "\n",
    "    #removing punctuations\n",
    "    p = re.compile('\\W')\n",
    "    q = re.sub(p,' ',q).strip()\n",
    "\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009452c7-3789-4bda-a6a3-a79f9b9bb0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_3132\\2176929224.py:154: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  q = BeautifulSoup(q)\n"
     ]
    }
   ],
   "source": [
    "new_df['question1'] = new_df['question1'].apply(preprocess)\n",
    "new_df['question2'] = new_df['question2'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0800d488-546f-4355-a238-61d219dcca62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "098a4602-df3f-46ad-86bb-2913d86c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f1aa03-7424-46d1-a060-8e84366eb31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ed11549-f4d6-4d04-9893-1887dccc1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['q1_len'] = new_df['question1'].str.len()\n",
    "new_df['q2_len'] = new_df['question2'].str.len()\n",
    "new_df['q1_words'] = new_df['question1'].apply(lambda r : len(r.split(\" \")))\n",
    "new_df['q2_words'] = new_df['question2'].apply(lambda r : len(r.split(\" \")))\n",
    "def getCommonWords(row):\n",
    "    w1 = set(map(lambda word : word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word : word.lower().strip(), row['question2'].split(\" \")))\n",
    "    w = (w1 & w2)\n",
    "    return len(w)\n",
    "new_df['common_words'] = new_df.apply(getCommonWords, axis=1)\n",
    "def get_totalWords(row):\n",
    "    w1 = set(map(lambda word : word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word : word.lower().strip(), row['question2'].split(\" \")))\n",
    "    l1 = len(w1)\n",
    "    l2 = len(w2)\n",
    "    return (l1+l2)\n",
    "new_df['words_count'] = new_df.apply(get_totalWords, axis=1)\n",
    "new_df['word_share'] = round(new_df['common_words']/new_df['words_count'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "343a22df-98c2-4275-b7e7-5425241892e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_tokenFeatures(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    safe_div = 0.0001 #to avoid overflow\n",
    "    stopWords = stopwords.words(\"english\")\n",
    "    tokenFeatures = [0.0]*8\n",
    "\n",
    "    # Converting the sentences to tokens\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if(len(q1_tokens) == 0 or len(q2_tokens) == 0):\n",
    "        return tokenFeatures\n",
    "\n",
    "    # Stopwords\n",
    "    q1_stops = set([word for word in q1_tokens if word in stopWords])\n",
    "    q2_stops = set([word for word in q2_tokens if word in stopWords])\n",
    "    # Non-stopwords\n",
    "    q1_words = set([word for word in q1_tokens if word not in stopWords])\n",
    "    q2_words = set([word for word in q2_tokens if word not in stopWords])\n",
    "\n",
    "    # count of common tokens in ques pair\n",
    "    common_tokens_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    # count of common non-stopwords in ques pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    # count of common stopwords in ques pair\n",
    "    common_stopwords_count = len(q1_stops.intersection(q2_stops))\n",
    "\n",
    "    # 1. the ratio of the number of common words to the length of the smaller question\n",
    "    tokenFeatures[0] = common_word_count / (min(len(q1_words),len(q2_words)) + safe_div)\n",
    "    # 2. the ratio of the number of common words to the length of the larger question\n",
    "    tokenFeatures[1] = common_word_count / (max(len(q1_words),len(q2_words)) + safe_div)\n",
    "    # 3. the ratio of the number of common stop words to the smaller stop word count among the two questions\n",
    "    tokenFeatures[2] = common_stopwords_count / (min(len(q1_stops),len(q2_stops)) + safe_div)\n",
    "    # 4. the ratio of the number of common stop words to the larger stop word count among the two questions\n",
    "    tokenFeatures[3] =  common_stopwords_count / (max(len(q1_stops),len(q2_stops)) + safe_div)\n",
    "    # 5. the ratio of the number of common tokens to the smaller token count among the two questions\n",
    "    tokenFeatures[4] = common_tokens_count / (min(len(q1_tokens),len(q2_tokens)) + safe_div)\n",
    "    # 6. the ratio of the number of common tokens to the larger token count among the two questions\n",
    "    tokenFeatures[5] = common_tokens_count / (max(len(q1_tokens),len(q2_tokens)) + safe_div)\n",
    "    # 7. last word of both questions is same or not\n",
    "    tokenFeatures[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    # 8. First word of both questions is same or not\n",
    "    tokenFeatures[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return tokenFeatures\n",
    "\n",
    "tokenFeatures = new_df.apply(get_tokenFeatures, axis=1)\n",
    "\n",
    "new_df[\"cwc_min\"] = list(map(lambda x: x[0], tokenFeatures))\n",
    "new_df[\"cwc_max\"] = list(map(lambda x: x[1], tokenFeatures))\n",
    "new_df[\"csc_min\"] = list(map(lambda x: x[2], tokenFeatures))\n",
    "new_df[\"csc_max\"] = list(map(lambda x: x[3], tokenFeatures))\n",
    "new_df[\"ctc_min\"] = list(map(lambda x: x[4], tokenFeatures))\n",
    "new_df[\"ctc_max\"] = list(map(lambda x: x[5], tokenFeatures))\n",
    "new_df[\"last_word_eq\"] = list(map(lambda x: x[6], tokenFeatures))\n",
    "new_df[\"first_word_eq\"] = list(map(lambda x: x[7], tokenFeatures))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c61ea7-d7ae-4966-979d-ca4c52103773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "def get_lengthFeatures(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    lengthFeatures = [0.0]*3\n",
    "    # converting to tokens\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    if len(q1_tokens)==0 or len(q2_tokens)==0 :\n",
    "        return lengthFeatures\n",
    "    # 1. Mean length : Mean of the length of the two questions\n",
    "    lengthFeatures[0] = (len(q1_tokens)+len(q2_tokens))/2\n",
    "    # 2. abs_len_diff: Absolute difference between the length of the two questions \n",
    "    lengthFeatures[1] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    # 3. longest_substr_ratio: Ratio of the length of the longest substring among the two questions to the length of the smaller question\n",
    "    strs = list(distance.lcsubstrings(q1,q2))\n",
    "    lengthFeatures[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "\n",
    "    return lengthFeatures\n",
    "\n",
    "\n",
    "lengthFeatures = new_df.apply(get_lengthFeatures, axis=1)\n",
    "\n",
    "new_df['mean_len'] = list(map(lambda x : x[0], lengthFeatures))\n",
    "new_df['abs_len_diff'] = list(map(lambda x : x[1], lengthFeatures))\n",
    "new_df['longest_substr_ratio'] = list(map(lambda x : x[2], lengthFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0608d6d-d88e-493a-97b1-dfa9a8f093fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def get_fuzzyFeatures(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    fuzzyFeatures = [0.0]*4\n",
    "\n",
    "    # 1. fuzz_ratio: fuzz_ratio score from fuzzywuzzy\n",
    "    fuzzyFeatures[0] = fuzz.QRatio(q1,q2)\n",
    "    # 2. fuzz_partial_ratio: fuzz_partial_ratio from fuzzywuzzy\n",
    "    fuzzyFeatures[1] = fuzz.partial_ratio(q1,q2)\n",
    "    # 3. token_sort_ratio: token_sort_ratio from fuzzywuzzy\n",
    "    fuzzyFeatures[2] = fuzz.token_sort_ratio(q1,q2)\n",
    "    # 4. token_set_ratio: token_set_ratio from fuzzywuzzy\n",
    "    fuzzyFeatures[3] = fuzz.token_set_ratio(q1,q2)\n",
    "\n",
    "    return fuzzyFeatures\n",
    "\n",
    "fuzzyFeatures = new_df.apply(get_fuzzyFeatures,axis=1)\n",
    "new_df['fuzz_ratio'] = list(map(lambda x : x[0], fuzzyFeatures))\n",
    "new_df['fuzz_partial_ratio'] = list(map(lambda x : x[1], fuzzyFeatures))\n",
    "new_df['fuzz_sort_ratio'] = list(map(lambda x : x[2], fuzzyFeatures))\n",
    "new_df['token_set_ratio'] = list(map(lambda x : x[3], fuzzyFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "805a94a5-f957-4717-b9f3-0ac71ee7f317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4a0a68d-1a90-45e3-a18b-9f627830164c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_words</th>\n",
       "      <th>q2_words</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222905</th>\n",
       "      <td>222905</td>\n",
       "      <td>439350</td>\n",
       "      <td>439351</td>\n",
       "      <td>what is senior scientist salary in amsterdam</td>\n",
       "      <td>how do i select in ranji or under 19 from vara...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174308</th>\n",
       "      <td>174308</td>\n",
       "      <td>344378</td>\n",
       "      <td>344379</td>\n",
       "      <td>how can evaporated milk be substituted for con...</td>\n",
       "      <td>can you substitute condensed milk for evaporat...</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>279667</td>\n",
       "      <td>549801</td>\n",
       "      <td>549802</td>\n",
       "      <td>what purpose does the amplitude of an electric...</td>\n",
       "      <td>is guys attracts more to sexy shemale</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>38938</td>\n",
       "      <td>77572</td>\n",
       "      <td>77573</td>\n",
       "      <td>how much salad should you eat per meal</td>\n",
       "      <td>why would a tuna salad recipe say to mix until...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123887</th>\n",
       "      <td>123887</td>\n",
       "      <td>245475</td>\n",
       "      <td>245476</td>\n",
       "      <td>what are dowels in construction</td>\n",
       "      <td>can an entrepreneur be effective at building b...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "222905  222905  439350  439351   \n",
       "174308  174308  344378  344379   \n",
       "279667  279667  549801  549802   \n",
       "38938    38938   77572   77573   \n",
       "123887  123887  245475  245476   \n",
       "\n",
       "                                                question1  \\\n",
       "222905       what is senior scientist salary in amsterdam   \n",
       "174308  how can evaporated milk be substituted for con...   \n",
       "279667  what purpose does the amplitude of an electric...   \n",
       "38938              how much salad should you eat per meal   \n",
       "123887                    what are dowels in construction   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "222905  how do i select in ranji or under 19 from vara...             0   \n",
       "174308  can you substitute condensed milk for evaporat...             0   \n",
       "279667              is guys attracts more to sexy shemale             0   \n",
       "38938   why would a tuna salad recipe say to mix until...             0   \n",
       "123887  can an entrepreneur be effective at building b...             0   \n",
       "\n",
       "        q1_len  q2_len  q1_words  q2_words  ...   ctc_max  last_word_eq  \\\n",
       "222905      44      92         7        20  ...  0.052631             0   \n",
       "174308      57      69         9        13  ...  0.416663             0   \n",
       "279667      58      37        10         7  ...  0.000000             0   \n",
       "38938       38      60         8        12  ...  0.083333             0   \n",
       "123887      31     113         5        16  ...  0.000000             0   \n",
       "\n",
       "        first_word_eq  mean_len  abs_len_diff  longest_substr_ratio  \\\n",
       "222905              0      13.0            12              0.088889   \n",
       "174308              0      10.5             3              0.293103   \n",
       "279667              0       8.5             3              0.078947   \n",
       "38938               0      10.0             4              0.179487   \n",
       "123887              0      10.0            10              0.156250   \n",
       "\n",
       "        fuzz_ratio  fuzz_partial_ratio  fuzz_sort_ratio  token_set_ratio  \n",
       "222905          25                  36               27               20  \n",
       "174308          41                  50               78               85  \n",
       "279667          23                  37               27               27  \n",
       "38938           41                  42               43               41  \n",
       "123887          21                  48               28               30  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d401d4b9-a43d-4602-a1ba-951316b9101c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 22)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2','is_duplicate'])\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02f1dba7-ccc0-426d-a344-5e2f6c4a4c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_words</th>\n",
       "      <th>q2_words</th>\n",
       "      <th>common_words</th>\n",
       "      <th>words_count</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222905</th>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174308</th>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123887</th>\n",
       "      <td>31</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q1_len  q2_len  q1_words  q2_words  common_words  words_count  \\\n",
       "222905      44      92         7        20             1           26   \n",
       "174308      57      69         9        13             5           19   \n",
       "279667      58      37        10         7             0           17   \n",
       "38938       38      60         8        12             1           20   \n",
       "123887      31     113         5        16             0           18   \n",
       "\n",
       "        word_share   cwc_min   cwc_max   csc_min  ...   ctc_max  last_word_eq  \\\n",
       "222905        0.04  0.000000  0.000000  0.333322  ...  0.052631             0   \n",
       "174308        0.26  0.749981  0.749981  0.499988  ...  0.416663             0   \n",
       "279667        0.00  0.000000  0.000000  0.000000  ...  0.000000             0   \n",
       "38938         0.05  0.199996  0.142855  0.000000  ...  0.083333             0   \n",
       "123887        0.00  0.000000  0.000000  0.000000  ...  0.000000             0   \n",
       "\n",
       "        first_word_eq  mean_len  abs_len_diff  longest_substr_ratio  \\\n",
       "222905              0      13.0            12              0.088889   \n",
       "174308              0      10.5             3              0.293103   \n",
       "279667              0       8.5             3              0.078947   \n",
       "38938               0      10.0             4              0.179487   \n",
       "123887              0      10.0            10              0.156250   \n",
       "\n",
       "        fuzz_ratio  fuzz_partial_ratio  fuzz_sort_ratio  token_set_ratio  \n",
       "222905          25                  36               27               20  \n",
       "174308          41                  50               78               85  \n",
       "279667          23                  37               27               27  \n",
       "38938           41                  42               43               41  \n",
       "123887          21                  48               28               30  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "562bdf90-cafe-4db0-99b7-a67888b56998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222905</th>\n",
       "      <td>what is senior scientist salary in amsterdam</td>\n",
       "      <td>how do i select in ranji or under 19 from vara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174308</th>\n",
       "      <td>how can evaporated milk be substituted for con...</td>\n",
       "      <td>can you substitute condensed milk for evaporat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>what purpose does the amplitude of an electric...</td>\n",
       "      <td>is guys attracts more to sexy shemale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>how much salad should you eat per meal</td>\n",
       "      <td>why would a tuna salad recipe say to mix until...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123887</th>\n",
       "      <td>what are dowels in construction</td>\n",
       "      <td>can an entrepreneur be effective at building b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "222905       what is senior scientist salary in amsterdam   \n",
       "174308  how can evaporated milk be substituted for con...   \n",
       "279667  what purpose does the amplitude of an electric...   \n",
       "38938              how much salad should you eat per meal   \n",
       "123887                    what are dowels in construction   \n",
       "\n",
       "                                                question2  \n",
       "222905  how do i select in ranji or under 19 from vara...  \n",
       "174308  can you substitute condensed milk for evaporat...  \n",
       "279667              is guys attracts more to sexy shemale  \n",
       "38938   why would a tuna salad recipe say to mix until...  \n",
       "123887  can an entrepreneur be effective at building b...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_df = new_df[['question1','question2']]\n",
    "ques_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09d7f785-8eee-423e-b626-edc1325e9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using TF_IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e16d1edf-fa21-471b-b442-e5a16251ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
    "q1_arr,q2_arr = np.vsplit(tfidfvectorizer.fit_transform(questions).toarray(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a2fdb92-b603-45f7-a880-02455a32ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df1 = pd.DataFrame(q1_arr, index = ques_df.index) # data frame having embeddings of questions from question1\n",
    "temp_df2 = pd.DataFrame(q2_arr, index = ques_df.index) # data frame having embeddings of questions from question2\n",
    "temp_df = pd.concat([temp_df1,temp_df2], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f6e8956-b2f1-440d-84ff-91ffdad35110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9492a2e7-0c96-4b49-870e-ba289cadf535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222905</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9    ...  990  991  992  \\\n",
       "222905  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "174308  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "279667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "38938   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "123887  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "        993       994  995  996  997  998  999  \n",
       "222905  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "174308  0.0  0.177773  0.0  0.0  0.0  0.0  0.0  \n",
       "279667  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "38938   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "123887  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3086d272-e77d-4e70-81fc-2ddaf7eac96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([final_df,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e2b3004-f3f1-4e83-9a46-7c6e050f6e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2022)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c1cc4e2-3d50-48b5-8e31-e5a3b9f54756",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['is_duplicate'] = new_df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccdfac86-3dd3-4450-8ea3-47c2d2a1482e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_words</th>\n",
       "      <th>q2_words</th>\n",
       "      <th>common_words</th>\n",
       "      <th>words_count</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222905</th>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174308</th>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38938</th>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123887</th>\n",
       "      <td>31</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2023 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q1_len  q2_len  q1_words  q2_words  common_words  words_count  \\\n",
       "222905      44      92         7        20             1           26   \n",
       "174308      57      69         9        13             5           19   \n",
       "279667      58      37        10         7             0           17   \n",
       "38938       38      60         8        12             1           20   \n",
       "123887      31     113         5        16             0           18   \n",
       "\n",
       "        word_share   cwc_min   cwc_max   csc_min  ...  991  992  993  \\\n",
       "222905        0.04  0.000000  0.000000  0.333322  ...  0.0  0.0  0.0   \n",
       "174308        0.26  0.749981  0.749981  0.499988  ...  0.0  0.0  0.0   \n",
       "279667        0.00  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0   \n",
       "38938         0.05  0.199996  0.142855  0.000000  ...  0.0  0.0  0.0   \n",
       "123887        0.00  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0   \n",
       "\n",
       "             994  995  996  997  998  999  is_duplicate  \n",
       "222905  0.000000  0.0  0.0  0.0  0.0  0.0             0  \n",
       "174308  0.177773  0.0  0.0  0.0  0.0  0.0             0  \n",
       "279667  0.000000  0.0  0.0  0.0  0.0  0.0             0  \n",
       "38938   0.000000  0.0  0.0  0.0  0.0  0.0             0  \n",
       "123887  0.000000  0.0  0.0  0.0  0.0  0.0             0  \n",
       "\n",
       "[5 rows x 2023 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86e628cb-84cf-46e1-8afa-6951cd1e1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('02_new_tfidf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72c5aea-ada7-4f32-bf17-5cd38fde8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv('new_tfidf.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d026e-230e-495d-b825-955713f5be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(temp_df.iloc[:,0:-1].values,temp_df.iloc[:,-1].values,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8945052-cf66-4d78-bfa8-9c2d79ff4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb22360-ba84-4ef2-847c-0b051287a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "xr = XGBRegressor()\n",
    "xr.fit(x_train,y_train)\n",
    "y_pred = xr.predict(x_test)\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af680c-f582-4d5d-b7df-f44b8a3f01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# import gensim.downloader as api\n",
    "# glove_model = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e0123-6b5a-453f-b55b-2f03817fa659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
    "# def get_sentence_embedding(sentence):\n",
    "#     embedding = []\n",
    "#     for word in sentence.split():\n",
    "#         if word in glove_model:\n",
    "#             embedding.append(glove_model[word])\n",
    "#     if embedding:\n",
    "#         return np.mean(embedding, axis=0)\n",
    "#     else:\n",
    "#         return np.zeros_like(glove_model.vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7f102-e488-4367-bc2d-fbccd3e3eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ques_df['question1_embedding'] = ques_df['question1'].apply(get_sentence_embedding)\n",
    "# ques_df['question2_embedding'] = ques_df['question2'].apply(get_sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117875b0-08b5-415f-8887-8573943ddd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #*****************************************************************************\n",
    "# q1_arr,q2_arr = np.vsplit(np.array([get_sentence_embedding(question) for question in questions]),2)\n",
    "# temp_df1 = pd.DataFrame(q1_arr, index = ques_df.index) # data frame having embeddings of questions from question1\n",
    "# temp_df2 = pd.DataFrame(q2_arr, index = ques_df.index) # data frame having embeddings of questions from question2\n",
    "# temp_df = pd.concat([temp_df1,temp_df2], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb263a-34c4-48cc-aa7e-def5e726dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133bb82-62c0-4019-a25b-5599521e73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.concat([final_df,temp_df],axis=1)\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01791d7-77c9-4a37-a981-9281a653a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae663f96-9407-4a85-8519-a3abe8f4b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test = train_test_split(final_df.iloc[:,0:-1].values,final_df.iloc[:,-1].values,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67805884-27b1-4dc0-9658-f855eab83297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# rf = RandomForestClassifier()\n",
    "# rf.fit(x_train,y_train)\n",
    "# y_pred = rf.predict(x_test)\n",
    "# accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
